name: Process Wikipedia Articles for NYC Landmarks

on:
  workflow_dispatch:
    inputs:
      landmark_ids:
        description: "Comma-separated list of landmark IDs to process (leave empty for all landmarks)"
        required: false
        default: ""
      limit:
        description: "Maximum number of landmarks to process (for testing)"
        required: false
        default: "0"
      chunk_size:
        description: "Text chunk size in characters"
        required: false
        default: "1000"
      chunk_overlap:
        description: "Overlap between chunks in characters"
        required: false
        default: "200"
      parallel:
        description: "Run processing in parallel"
        required: false
        default: true
        type: boolean
      workers:
        description: "Number of parallel workers (if parallel is true)"
        required: false
        default: "4"
      index_name:
        description: "Pinecone index name (leave empty for default in settings)"
        required: false
        default: ""
      force_reprocess:
        description: "Force reprocessing of articles already in the index"
        required: false
        default: false
        type: boolean
      skip_verification:
        description: "Skip verification step after processing"
        required: false
        default: false
        type: boolean
      verbose:
        description: "Enable verbose logging"
        required: false
        default: true
        type: boolean

jobs:
  process-wikipedia:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
          pip install -r requirements.txt

      - name: Configure environment
        run: |
          {
            echo "PINECONE_API_KEY=${{ secrets.PINECONE_API_KEY }}"
            echo "PINECONE_ENVIRONMENT=${{ secrets.PINECONE_ENVIRONMENT }}"
            echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}"
            echo "COREDATASTORE_API_KEY=${{ secrets.COREDATASTORE_API_KEY }}"

            # Add custom index name if provided
            if [[ -n "${{ github.event.inputs.index_name }}" ]]; then
              echo "PINECONE_INDEX_NAME=${{ github.event.inputs.index_name }}"
            fi
          } >> "$GITHUB_ENV"

      - name: Check API connections
        run: |
          if ! python scripts/ci/test_pinecone_connection.py; then
            echo "Failed to connect to Pinecone API"
            exit 1
          fi

      - name: Process Wikipedia articles
        id: process_articles
        run: |
          # Build command arguments using array for proper handling
          ARGS=()

          # Add landmark IDs if specified
          if [[ -n "${{ github.event.inputs.landmark_ids }}" ]]; then
            ARGS+=(--landmark-ids "${{ github.event.inputs.landmark_ids }}")
          fi

          # Add limit if specified
          if [[ "${{ github.event.inputs.limit }}" != "0" ]]; then
            ARGS+=(--limit "${{ github.event.inputs.limit }}")
          fi

          # Add chunk configuration
          ARGS+=(
            --chunk-size "${{ github.event.inputs.chunk_size }}"
            --chunk-overlap "${{ github.event.inputs.chunk_overlap }}"
          )

          # Add parallel processing if enabled
          if [[ "${{ github.event.inputs.parallel }}" == "true" ]]; then
            ARGS+=(--parallel --workers "${{ github.event.inputs.workers }}")
          fi

          # Add force reprocess if enabled
          if [[ "${{ github.event.inputs.force_reprocess }}" == "true" ]]; then
            ARGS+=(--force-reprocess)
          fi

          # Add verbose flag if enabled
          if [[ "${{ github.event.inputs.verbose }}" == "true" ]]; then
            ARGS+=(--verbose)
          fi

          # Run the processing script
          echo "Running: python scripts/ci/process_wikipedia_articles.py ${ARGS[*]}"
          python scripts/ci/process_wikipedia_articles.py "${ARGS[@]}"

          # Create a summary file for artifacts
          {
            echo "# Wikipedia Processing Results"
            echo "## Configuration"
            echo "- Landmark IDs: ${{ github.event.inputs.landmark_ids || 'All landmarks' }}"
            echo "- Chunk size: ${{ github.event.inputs.chunk_size }}"
            echo "- Chunk overlap: ${{ github.event.inputs.chunk_overlap }}"
            echo "- Parallel processing: ${{ github.event.inputs.parallel }}"
            echo "- Workers: ${{ github.event.inputs.workers }}"
            echo "- Force reprocess: ${{ github.event.inputs.force_reprocess }}"
            if [[ -n "${{ github.event.inputs.index_name }}" ]]; then
              echo "- Pinecone index: ${{ github.event.inputs.index_name }}"
            fi

            echo "Processing completed successfully."
          } > wiki_processing_summary.md

      - name: Verify Wikipedia integration
        if: ${{ github.event.inputs.skip_verification != 'true' }}
        run: |
          echo "Verifying Wikipedia integration..."
          # Create verification directory
          mkdir -p verification_results

          # Run verification script
          python scripts/ci/verify_wikipedia_imports.py --verbose --coverage-report --output-dir verification_results

          # Add verification results to summary
          {
            echo "## Verification Results"
            echo "See attached verification report for details."
          } >> wiki_processing_summary.md

      - name: Upload processing results
        uses: actions/upload-artifact@v4
        with:
          name: wikipedia-processing-results
          path: |
            wiki_processing_summary.md
            verification_results/
            logs/
          if-no-files-found: warn
