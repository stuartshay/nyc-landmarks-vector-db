{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Landmarks Vector Database Statistics\n",
    "\n",
    "This notebook provides a comprehensive analysis of the NYC Landmarks data stored in the Pinecone vector database. It examines the vectors, metadata distribution, and overall statistics of the embeddings to give insights about the landmarks collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "First, we'll import the necessary libraries and set up connections to the Pinecone database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Tuple, Optional\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Data analysis libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# For map visualizations\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Vector analysis\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Add project directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project modules\n",
    "from nyc_landmarks.config.settings import settings\n",
    "from nyc_landmarks.vectordb.pinecone_db import PineconeDB\n",
    "from nyc_landmarks.db.db_client import DbClient\n",
    "\n",
    "# We're using the fetch_all_lpc_reports function instead of the non-existent LandmarkReportFetcher\n",
    "from nyc_landmarks.db.fetchers import fetch_all_lpc_reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection\n",
    "\n",
    "Connect to the Pinecone database and verify the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nyc_landmarks.db.db_client:Using CoreDataStore API client\n",
      "INFO:nyc_landmarks.db.coredatastore_api:Initialized CoreDataStore API client\n",
      "INFO:nyc_landmarks.db.coredatastore_api:Initialized CoreDataStore API client\n",
      "INFO:nyc_landmarks.vectordb.pinecone_db:Initialized Pinecone in environment: us-central1-gcp\n",
      "INFO:nyc_landmarks.vectordb.pinecone_db:Initialized Pinecone in environment: us-central1-gcp\n",
      "INFO:nyc_landmarks.vectordb.pinecone_db:Connected to Pinecone index: nyc-landmarks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully connected to Pinecone index: nyc-landmarks\n",
      "Namespace: landmarks\n",
      "Dimensions: 1536\n",
      "Metric: cosine\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Pinecone database client\n",
    "pinecone_db = PineconeDB()\n",
    "\n",
    "# Check if the connection was successful\n",
    "if pinecone_db.index:\n",
    "    print(f\"✅ Successfully connected to Pinecone index: {pinecone_db.index_name}\")\n",
    "    print(f\"Namespace: {pinecone_db.namespace}\")\n",
    "    print(f\"Dimensions: {pinecone_db.dimensions}\")\n",
    "    print(f\"Metric: {pinecone_db.metric}\")\n",
    "else:\n",
    "    print(\"❌ Failed to connect to Pinecone. Check your credentials and network connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Statistics\n",
    "\n",
    "Retrieve basic statistics about the Pinecone index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:nyc_landmarks.vectordb.pinecone_db:Error getting index stats: 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Index Statistics:\n",
      "Dimension: N/A\n",
      "Index Fullness: N/A\n",
      "\n",
      "🔢 Total Vector Count: 0\n",
      "\n",
      "📁 Namespace Statistics:\n"
     ]
    }
   ],
   "source": [
    "# Get index statistics\n",
    "index_stats = pinecone_db.get_index_stats()\n",
    "\n",
    "# Display the statistics in a more readable format\n",
    "print(\"\\n📊 Index Statistics:\")\n",
    "print(f\"Dimension: {index_stats.get('dimension', 'N/A')}\")\n",
    "print(f\"Index Fullness: {index_stats.get('index_fullness', 'N/A')}\")\n",
    "\n",
    "# Extract namespace information\n",
    "namespaces = index_stats.get('namespaces', {})\n",
    "total_vector_count = sum(ns.get('vector_count', 0) for ns in namespaces.values())\n",
    "\n",
    "print(f\"\\n🔢 Total Vector Count: {total_vector_count:,}\")\n",
    "print(\"\\n📁 Namespace Statistics:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for namespace stats\n",
    "namespace_data = []\n",
    "\n",
    "for ns_name, ns_stats in namespaces.items():\n",
    "    vector_count = ns_stats.get('vector_count', 0)\n",
    "    percentage = (vector_count / total_vector_count * 100) if total_vector_count > 0 else 0\n",
    "    namespace_data.append({\n",
    "        'Namespace': ns_name if ns_name else 'default',\n",
    "        'Vector Count': vector_count,\n",
    "        'Percentage': percentage\n",
    "    })\n",
    "\n",
    "namespace_df = pd.DataFrame(namespace_data)\n",
    "if not namespace_df.empty:\n",
    "    namespace_df = namespace_df.sort_values('Vector Count', ascending=False).reset_index(drop=True)\n",
    "    display(namespace_df)\n",
    "else:\n",
    "    print(\"No namespace data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize namespace distribution\n",
    "if not namespace_df.empty and len(namespace_df) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(namespace_df['Namespace'], namespace_df['Vector Count'], color='skyblue')\n",
    "    plt.title('Vector Count by Namespace')\n",
    "    plt.xlabel('Namespace')\n",
    "    plt.ylabel('Vector Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add count labels on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                f'{int(height):,}',\n",
    "                ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Metadata Analysis\n",
    "\n",
    "Let's analyze the metadata associated with the vectors to understand the distribution of landmark properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample vectors and retrieve metadata\n",
    "def sample_vectors(pinecone_db, sample_size=100):\n",
    "    \"\"\"\n",
    "    Sample vectors from the Pinecone database to analyze metadata.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get a sample of vectors from the index\n",
    "        # Since Pinecone doesn't have a direct \"sample\" function,\n",
    "        # we'll query with a random vector to get diverse results\n",
    "        random_vector = np.random.rand(pinecone_db.dimensions).tolist()\n",
    "        \n",
    "        # Set a high top_k to get a good sample size\n",
    "        results = pinecone_db.query_vectors(\n",
    "            query_vector=random_vector,\n",
    "            top_k=sample_size,\n",
    "            filter_dict=None\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error sampling vectors: {e}\")\n",
    "        return []\n",
    "\n",
    "# Sample vectors for analysis\n",
    "sample_size = 200  # Adjust based on your database size\n",
    "vector_samples = sample_vectors(pinecone_db, sample_size)\n",
    "\n",
    "print(f\"Retrieved {len(vector_samples)} vector samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze metadata fields\n",
    "if vector_samples:\n",
    "    # Extract all metadata fields\n",
    "    all_metadata = [sample.get('metadata', {}) for sample in vector_samples]\n",
    "    \n",
    "    # Count metadata fields\n",
    "    field_counts = Counter()\n",
    "    for metadata in all_metadata:\n",
    "        for key in metadata.keys():\n",
    "            field_counts[key] += 1\n",
    "    \n",
    "    # Create DataFrame for field distribution\n",
    "    field_df = pd.DataFrame({\n",
    "        'Field': list(field_counts.keys()),\n",
    "        'Count': list(field_counts.values()),\n",
    "        'Percentage': [count/len(all_metadata)*100 for count in field_counts.values()]\n",
    "    }).sort_values('Count', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Display field distribution\n",
    "    display(field_df)\n",
    "    \n",
    "    # Visualize top 10 metadata fields\n",
    "    top_fields = field_df.head(10)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(top_fields['Field'], top_fields['Count'], color='lightgreen')\n",
    "    plt.title('Top 10 Metadata Fields')\n",
    "    plt.xlabel('Metadata Field')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add count labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No vector samples available for metadata analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographical Distribution\n",
    "\n",
    "If the vectors contain location information, let's visualize the geographical distribution of landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract geographical information and create a map\n",
    "def create_landmark_map(vector_samples):\n",
    "    \"\"\"\n",
    "    Create a map visualization of landmarks with geographical information.\n",
    "    \"\"\"\n",
    "    # Extract latitude and longitude information if available\n",
    "    geo_data = []\n",
    "    for sample in vector_samples:\n",
    "        metadata = sample.get('metadata', {})\n",
    "        \n",
    "        # Check if the required fields exist - names may vary by your schema\n",
    "        lat = metadata.get('latitude') or metadata.get('lat')\n",
    "        lng = metadata.get('longitude') or metadata.get('lng')\n",
    "        name = metadata.get('name') or metadata.get('title') or \"Unknown\"\n",
    "        \n",
    "        if lat and lng:\n",
    "            try:\n",
    "                geo_data.append({\n",
    "                    'name': name,\n",
    "                    'lat': float(lat),\n",
    "                    'lng': float(lng),\n",
    "                    'metadata': metadata\n",
    "                })\n",
    "            except (ValueError, TypeError):\n",
    "                # Skip if conversion to float fails\n",
    "                pass\n",
    "    \n",
    "    # Create map if we have geo data\n",
    "    if geo_data:\n",
    "        # Create a dataframe for the geographical data\n",
    "        geo_df = pd.DataFrame(geo_data)\n",
    "        \n",
    "        # Center the map on the mean coordinates\n",
    "        center_lat = geo_df['lat'].mean()\n",
    "        center_lng = geo_df['lng'].mean()\n",
    "        \n",
    "        # Create a map\n",
    "        m = folium.Map(location=[center_lat, center_lng], zoom_start=12)\n",
    "        \n",
    "        # Add a marker cluster\n",
    "        marker_cluster = MarkerCluster().add_to(m)\n",
    "        \n",
    "        # Add markers for each landmark\n",
    "        for _, row in geo_df.iterrows():\n",
    "            popup_html = f\"<b>{row['name']}</b>\"\n",
    "            folium.Marker(\n",
    "                location=[row['lat'], row['lng']],\n",
    "                popup=folium.Popup(popup_html, max_width=300),\n",
    "                icon=folium.Icon(color='blue', icon='info-sign')\n",
    "            ).add_to(marker_cluster)\n",
    "        \n",
    "        # Display the map\n",
    "        return m\n",
    "    else:\n",
    "        print(\"No geographical data found in the vector metadata\")\n",
    "        return None\n",
    "\n",
    "# Create and display the map\n",
    "landmark_map = create_landmark_map(vector_samples)\n",
    "if landmark_map:\n",
    "    display(landmark_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a comprehensive analysis of the NYC Landmarks vector database. The analysis includes:\n",
    "\n",
    "1. Database size and vector counts by namespace\n",
    "2. Metadata distribution analysis\n",
    "3. Vector distribution across landmarks\n",
    "4. Vector clustering and dimensionality reduction visualization\n",
    "\n",
    "These insights help us understand the structure and content of the vector database, enabling better optimization and usage of the data for landmark information retrieval."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc-landmarks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
