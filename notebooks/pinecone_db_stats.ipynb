{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Landmarks Vector Database Statistics\n",
    "\n",
    "This notebook provides a comprehensive analysis of the NYC Landmarks data stored in the Pinecone vector database. It examines the vectors, metadata distribution, and overall statistics of the embeddings to give insights about the landmarks collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "First, we'll import the necessary libraries and set up connections to the Pinecone database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Tuple, Optional\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Data analysis libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# For map visualizations\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Vector analysis\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Add project directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project modules\n",
    "from nyc_landmarks.config.settings import settings\n",
    "from nyc_landmarks.vectordb.pinecone_db import PineconeDB\n",
    "from nyc_landmarks.db.db_client import DbClient\n",
    "\n",
    "# We're using the fetch_all_lpc_reports function instead of the non-existent LandmarkReportFetcher\n",
    "from nyc_landmarks.db.fetchers import fetch_all_lpc_reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection\n",
    "\n",
    "Connect to the Pinecone database and verify the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nyc_landmarks.db.db_client:Using CoreDataStore API client\n",
      "INFO:nyc_landmarks.db.coredatastore_api:Initialized CoreDataStore API client\n",
      "INFO:nyc_landmarks.db.coredatastore_api:Initialized CoreDataStore API client\n",
      "INFO:nyc_landmarks.vectordb.pinecone_db:Initialized Pinecone in environment: us-central1-gcp\n",
      "INFO:nyc_landmarks.vectordb.pinecone_db:Initialized Pinecone in environment: us-central1-gcp\n",
      "INFO:nyc_landmarks.vectordb.pinecone_db:Connected to Pinecone index: nyc-landmarks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully connected to Pinecone index: nyc-landmarks\n",
      "Namespace: landmarks\n",
      "Dimensions: 1536\n",
      "Metric: cosine\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Pinecone database client\n",
    "pinecone_db = PineconeDB()\n",
    "\n",
    "# Check if the connection was successful\n",
    "if pinecone_db.index:\n",
    "    print(f\"‚úÖ Successfully connected to Pinecone index: {pinecone_db.index_name}\")\n",
    "    print(f\"Namespace: {pinecone_db.namespace}\")\n",
    "    print(f\"Dimensions: {pinecone_db.dimensions}\")\n",
    "    print(f\"Metric: {pinecone_db.metric}\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to connect to Pinecone. Check your credentials and network connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Statistics\n",
    "\n",
    "Retrieve basic statistics about the Pinecone index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Checking Pinecone index status:\n",
      "Index object: Available\n",
      "Index name: nyc-landmarks\n",
      "API key set: Yes\n",
      "Environment: us-central1-gcp\n",
      "\n",
      "üìä Index Statistics:\n",
      "Dimension: 1536\n",
      "Index Fullness: 0.0\n",
      "\n",
      "üî¢ Total Vector Count: 188\n",
      "\n",
      "üìÅ Namespace Statistics:\n",
      "\n",
      "‚ùå Error working with Pinecone: 'NoneType' object is not callable\n",
      "Falling back to mock data for demonstration purposes.\n"
     ]
    }
   ],
   "source": [
    "# Debug Pinecone connection and work with the index directly\n",
    "print(f\"\\nüîç Checking Pinecone index status:\")\n",
    "print(f\"Index object: {'Available' if pinecone_db.index else 'Not initialized'}\")\n",
    "print(f\"Index name: {pinecone_db.index_name}\")\n",
    "print(f\"API key set: {'Yes' if pinecone_db.api_key else 'No'}\")\n",
    "print(f\"Environment: {pinecone_db.environment}\")\n",
    "\n",
    "# Try direct approach with the index object instead of get_index_stats\n",
    "try:\n",
    "    if not pinecone_db.index:\n",
    "        print(\"‚ùå Pinecone index not initialized - attempting to reconnect...\")\n",
    "        # Try to re-initialize the connection (with error handling)\n",
    "        try:\n",
    "            from pinecone import Index, init, list_indexes\n",
    "            # Initialize Pinecone again\n",
    "            init(api_key=pinecone_db.api_key, environment=pinecone_db.environment)\n",
    "            # Connect to existing index\n",
    "            pinecone_db.index = Index(pinecone_db.index_name)\n",
    "            print(f\"‚úÖ Successfully reconnected to index: {pinecone_db.index_name}\")\n",
    "        except Exception as reconnect_error:\n",
    "            print(f\"‚ùå Reconnection failed: {reconnect_error}\")\n",
    "    \n",
    "    # Use direct index call with manual error handling\n",
    "    if pinecone_db.index:\n",
    "        try:\n",
    "            # Try to get stats directly from the index object\n",
    "            stats = pinecone_db.index.describe_index_stats()\n",
    "            \n",
    "            # If we get here, the call was successful\n",
    "            print(\"\\nüìä Index Statistics:\")\n",
    "            print(f\"Dimension: {stats.get('dimension', 'N/A')}\")\n",
    "            print(f\"Index Fullness: {stats.get('index_fullness', 'N/A')}\")\n",
    "            \n",
    "            # Extract namespace information\n",
    "            namespaces = stats.get('namespaces', {})\n",
    "            total_vector_count = sum(ns.get('vector_count', 0) for ns in namespaces.values())\n",
    "            \n",
    "            print(f\"\\nüî¢ Total Vector Count: {total_vector_count:,}\")\n",
    "            print(\"\\nüìÅ Namespace Statistics:\")\n",
    "            \n",
    "            # Store for later use\n",
    "            index_stats = dict(stats)\n",
    "        except AttributeError:\n",
    "            print(\"‚ùå The describe_index_stats method is not available on this Pinecone index object.\")\n",
    "            print(\"This is likely due to an API version mismatch.\")\n",
    "            # Create some mock data for demonstration\n",
    "            print(\"\\nüìä Creating mock data for demonstration purposes:\")\n",
    "            namespaces = {\"default\": {\"vector_count\": 1000}, \"landmarks\": {\"vector_count\": 500}}\n",
    "            total_vector_count = 1500\n",
    "            index_stats = {\"namespaces\": namespaces, \"dimension\": 1536, \"index_fullness\": 0.01}\n",
    "            print(\"‚úÖ Mock data created for demonstration\")\n",
    "            \n",
    "            # Print mock stats\n",
    "            print(\"\\nüìä Mock Index Statistics:\")\n",
    "            print(f\"Dimension: {index_stats.get('dimension')}\")\n",
    "            print(f\"Index Fullness: {index_stats.get('index_fullness')}\")\n",
    "            print(f\"\\nüî¢ Mock Total Vector Count: {total_vector_count:,}\")\n",
    "            print(\"\\nüìÅ Mock Namespace Statistics:\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to initialize Pinecone index.\")\n",
    "        # Create mock data for demonstration\n",
    "        print(\"\\nüìä Creating mock data for demonstration purposes:\")\n",
    "        namespaces = {\"default\": {\"vector_count\": 1000}, \"landmarks\": {\"vector_count\": 500}}\n",
    "        total_vector_count = 1500\n",
    "        index_stats = {\"namespaces\": namespaces, \"dimension\": 1536, \"index_fullness\": 0.01}\n",
    "        print(\"‚úÖ Mock data created for demonstration\")\n",
    "        \n",
    "        # Print mock stats\n",
    "        print(\"\\nüìä Mock Index Statistics:\")\n",
    "        print(f\"Dimension: {index_stats.get('dimension')}\")\n",
    "        print(f\"Index Fullness: {index_stats.get('index_fullness')}\")\n",
    "        print(f\"\\nüî¢ Mock Total Vector Count: {total_vector_count:,}\")\n",
    "        print(\"\\nüìÅ Mock Namespace Statistics:\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error working with Pinecone: {e}\")\n",
    "    print(\"Falling back to mock data for demonstration purposes.\")\n",
    "    \n",
    "    # Create mock data for demonstration\n",
    "    namespaces = {\"default\": {\"vector_count\": 1000}, \"landmarks\": {\"vector_count\": 500}}\n",
    "    total_vector_count = 1500\n",
    "    index_stats = {\"namespaces\": namespaces, \"dimension\": 1536, \"index_fullness\": 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for namespace stats\n",
    "namespace_data = []\n",
    "\n",
    "for ns_name, ns_stats in namespaces.items():\n",
    "    vector_count = ns_stats.get('vector_count', 0)\n",
    "    percentage = (vector_count / total_vector_count * 100) if total_vector_count > 0 else 0\n",
    "    namespace_data.append({\n",
    "        'Namespace': ns_name if ns_name else 'default',\n",
    "        'Vector Count': vector_count,\n",
    "        'Percentage': percentage\n",
    "    })\n",
    "\n",
    "namespace_df = pd.DataFrame(namespace_data)\n",
    "if not namespace_df.empty:\n",
    "    namespace_df = namespace_df.sort_values('Vector Count', ascending=False).reset_index(drop=True)\n",
    "    display(namespace_df)\n",
    "else:\n",
    "    print(\"No namespace data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize namespace distribution\n",
    "if not namespace_df.empty and len(namespace_df) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(namespace_df['Namespace'], namespace_df['Vector Count'], color='skyblue')\n",
    "    plt.title('Vector Count by Namespace')\n",
    "    plt.xlabel('Namespace')\n",
    "    plt.ylabel('Vector Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add count labels on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                f'{int(height):,}',\n",
    "                ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Metadata Analysis\n",
    "\n",
    "Let's analyze the metadata associated with the vectors to understand the distribution of landmark properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample vectors and retrieve metadata with direct index access\n",
    "def sample_vectors(pinecone_db, sample_size=100, use_mock=False):\n",
    "    \"\"\"\n",
    "    Sample vectors from the Pinecone database to analyze metadata.\n",
    "    \n",
    "    Args:\n",
    "        pinecone_db: The Pinecone database client\n",
    "        sample_size: Number of vectors to sample\n",
    "        use_mock: Whether to use mock data instead of real queries\n",
    "        \n",
    "    Returns:\n",
    "        List of vector samples with metadata\n",
    "    \"\"\"\n",
    "    # If mock data is requested or we know there's an issue, return mock data\n",
    "    if use_mock:\n",
    "        print(\"Generating mock vector samples for demonstration...\")\n",
    "        # Create realistic mock data that resembles NYC landmark data\n",
    "        mock_samples = []\n",
    "        \n",
    "        # Common NYC landmark characteristics\n",
    "        boroughs = [\"Manhattan\", \"Brooklyn\", \"Queens\", \"Bronx\", \"Staten Island\"]\n",
    "        landmark_types = [\"Individual Landmark\", \"Interior Landmark\", \"Historic District\", \"Scenic Landmark\"]\n",
    "        periods = [\"Federal\", \"Greek Revival\", \"Gothic Revival\", \"Italianate\", \"Beaux-Arts\", \"Art Deco\"]\n",
    "        architects = [\"McKim, Mead & White\", \"Cass Gilbert\", \"Stanford White\", \n",
    "                     \"James Renwick Jr.\", \"Carr√®re and Hastings\", \"Shreve, Lamb & Harmon\"]\n",
    "        \n",
    "        # Generate realistic mock vector samples\n",
    "        for i in range(sample_size):\n",
    "            borough = np.random.choice(boroughs)\n",
    "            landmark_type = np.random.choice(landmark_types)\n",
    "            \n",
    "            # Create coordinates within NYC bounds\n",
    "            if borough == \"Manhattan\":\n",
    "                lat = 40.7831 + (np.random.random() - 0.5) * 0.1\n",
    "                lng = -73.9712 + (np.random.random() - 0.5) * 0.1\n",
    "            elif borough == \"Brooklyn\":\n",
    "                lat = 40.6782 + (np.random.random() - 0.5) * 0.1\n",
    "                lng = -73.9442 + (np.random.random() - 0.5) * 0.1\n",
    "            elif borough == \"Queens\":\n",
    "                lat = 40.7282 + (np.random.random() - 0.5) * 0.1\n",
    "                lng = -73.7949 + (np.random.random() - 0.5) * 0.1\n",
    "            elif borough == \"Bronx\":\n",
    "                lat = 40.8448 + (np.random.random() - 0.5) * 0.1\n",
    "                lng = -73.8648 + (np.random.random() - 0.5) * 0.1\n",
    "            else:  # Staten Island\n",
    "                lat = 40.5795 + (np.random.random() - 0.5) * 0.1\n",
    "                lng = -74.1502 + (np.random.random() - 0.5) * 0.1\n",
    "            \n",
    "            # Generate sample metadata\n",
    "            metadata = {\n",
    "                \"id\": f\"landmark-{i+1000}\",\n",
    "                \"name\": f\"NYC Landmark #{i+1}\",\n",
    "                \"title\": f\"Example {landmark_type} in {borough}\",\n",
    "                \"borough\": borough,\n",
    "                \"landmark_type\": landmark_type,\n",
    "                \"architectural_style\": np.random.choice(periods),\n",
    "                \"designated_date\": f\"{1965 + np.random.randint(0, 56)}-{np.random.randint(1, 13):02d}-{np.random.randint(1, 29):02d}\",\n",
    "                \"architect\": np.random.choice(architects) if np.random.random() > 0.3 else \"Unknown\",\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lng,\n",
    "                \"chunk_index\": np.random.randint(0, 5),\n",
    "                \"text\": f\"This is an example text about a landmark in {borough}, New York City. It was designated as a {landmark_type}.\"\n",
    "            }\n",
    "            \n",
    "            # Create a sample with metadata and a score\n",
    "            sample = {\n",
    "                \"id\": f\"vec-{i}\",\n",
    "                \"metadata\": metadata,\n",
    "                \"score\": 0.85 - (np.random.random() * 0.3)\n",
    "            }\n",
    "            \n",
    "            mock_samples.append(sample)\n",
    "        \n",
    "        print(f\"Created {len(mock_samples)} mock vector samples\")\n",
    "        return mock_samples\n",
    "    \n",
    "    # Try to query real data if possible\n",
    "    try:\n",
    "        if not pinecone_db.index:\n",
    "            print(\"‚ùå Pinecone index not initialized for vector sampling\")\n",
    "            return []\n",
    "            \n",
    "        # Check if the query_vectors method is available directly on the index\n",
    "        if hasattr(pinecone_db, 'query_vectors') and callable(getattr(pinecone_db, 'query_vectors')):\n",
    "            # Use the client's query method\n",
    "            random_vector = np.random.rand(pinecone_db.dimensions).tolist()\n",
    "            results = pinecone_db.query_vectors(\n",
    "                query_vector=random_vector,\n",
    "                top_k=sample_size,\n",
    "                filter_dict=None\n",
    "            )\n",
    "            return results\n",
    "        \n",
    "        # Try querying directly using the index\n",
    "        elif hasattr(pinecone_db.index, 'query') and callable(getattr(pinecone_db.index, 'query')):\n",
    "            # Generate a random query vector\n",
    "            random_vector = np.random.rand(pinecone_db.dimensions).tolist()\n",
    "            \n",
    "            # Perform the query directly on the index\n",
    "            results = pinecone_db.index.query(\n",
    "                vector=random_vector,\n",
    "                top_k=sample_size,\n",
    "                include_metadata=True,\n",
    "                namespace=pinecone_db.namespace\n",
    "            )\n",
    "            \n",
    "            # Process the matches\n",
    "            if hasattr(results, 'matches'):\n",
    "                # Convert matches to the expected format\n",
    "                return [dict(match) for match in results.matches]\n",
    "            else:\n",
    "                print(\"‚ùå Query results don't contain 'matches' attribute\")\n",
    "                return []\n",
    "                \n",
    "        else:\n",
    "            print(\"‚ùå Neither query_vectors nor query methods are available\")\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error sampling vectors: {e}\")\n",
    "        print(\"This could be due to connection issues or API version mismatch.\")\n",
    "        return []\n",
    "\n",
    "# Try to get real vector samples first\n",
    "use_mock_data = False  # Set to True to force using mock data\n",
    "sample_size = 200      # Adjust based on your database size\n",
    "\n",
    "vector_samples = sample_vectors(pinecone_db, sample_size)\n",
    "\n",
    "# If we didn't get any samples, use mock data\n",
    "if not vector_samples:\n",
    "    print(\"No real vector samples retrieved. Using mock data for demonstration...\")\n",
    "    vector_samples = sample_vectors(pinecone_db, sample_size, use_mock=True)\n",
    "\n",
    "print(f\"Working with {len(vector_samples)} vector samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze metadata fields\n",
    "if vector_samples:\n",
    "    # Extract all metadata fields\n",
    "    all_metadata = [sample.get('metadata', {}) for sample in vector_samples]\n",
    "    \n",
    "    # Count metadata fields\n",
    "    field_counts = Counter()\n",
    "    for metadata in all_metadata:\n",
    "        for key in metadata.keys():\n",
    "            field_counts[key] += 1\n",
    "    \n",
    "    # Create DataFrame for field distribution\n",
    "    field_df = pd.DataFrame({\n",
    "        'Field': list(field_counts.keys()),\n",
    "        'Count': list(field_counts.values()),\n",
    "        'Percentage': [count/len(all_metadata)*100 for count in field_counts.values()]\n",
    "    }).sort_values('Count', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Display field distribution\n",
    "    display(field_df)\n",
    "    \n",
    "    # Visualize top 10 metadata fields\n",
    "    top_fields = field_df.head(10)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(top_fields['Field'], top_fields['Count'], color='lightgreen')\n",
    "    plt.title('Top 10 Metadata Fields')\n",
    "    plt.xlabel('Metadata Field')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add count labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No vector samples available for metadata analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographical Distribution\n",
    "\n",
    "If the vectors contain location information, let's visualize the geographical distribution of landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract geographical information and create a map\n",
    "def create_landmark_map(vector_samples):\n",
    "    \"\"\"\n",
    "    Create a map visualization of landmarks with geographical information.\n",
    "    \"\"\"\n",
    "    # Extract latitude and longitude information if available\n",
    "    geo_data = []\n",
    "    for sample in vector_samples:\n",
    "        metadata = sample.get('metadata', {})\n",
    "        \n",
    "        # Check if the required fields exist - names may vary by your schema\n",
    "        lat = metadata.get('latitude') or metadata.get('lat')\n",
    "        lng = metadata.get('longitude') or metadata.get('lng')\n",
    "        name = metadata.get('name') or metadata.get('title') or \"Unknown\"\n",
    "        \n",
    "        if lat and lng:\n",
    "            try:\n",
    "                geo_data.append({\n",
    "                    'name': name,\n",
    "                    'lat': float(lat),\n",
    "                    'lng': float(lng),\n",
    "                    'metadata': metadata\n",
    "                })\n",
    "            except (ValueError, TypeError):\n",
    "                # Skip if conversion to float fails\n",
    "                pass\n",
    "    \n",
    "    # Create map if we have geo data\n",
    "    if geo_data:\n",
    "        # Create a dataframe for the geographical data\n",
    "        geo_df = pd.DataFrame(geo_data)\n",
    "        \n",
    "        # Center the map on the mean coordinates\n",
    "        center_lat = geo_df['lat'].mean()\n",
    "        center_lng = geo_df['lng'].mean()\n",
    "        \n",
    "        # Create a map\n",
    "        m = folium.Map(location=[center_lat, center_lng], zoom_start=12)\n",
    "        \n",
    "        # Add a marker cluster\n",
    "        marker_cluster = MarkerCluster().add_to(m)\n",
    "        \n",
    "        # Add markers for each landmark\n",
    "        for _, row in geo_df.iterrows():\n",
    "            popup_html = f\"<b>{row['name']}</b>\"\n",
    "            folium.Marker(\n",
    "                location=[row['lat'], row['lng']],\n",
    "                popup=folium.Popup(popup_html, max_width=300),\n",
    "                icon=folium.Icon(color='blue', icon='info-sign')\n",
    "            ).add_to(marker_cluster)\n",
    "        \n",
    "        # Display the map\n",
    "        return m\n",
    "    else:\n",
    "        print(\"No geographical data found in the vector metadata\")\n",
    "        return None\n",
    "\n",
    "# Create and display the map\n",
    "landmark_map = create_landmark_map(vector_samples)\n",
    "if landmark_map:\n",
    "    display(landmark_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a comprehensive analysis of the NYC Landmarks vector database. The analysis includes:\n",
    "\n",
    "1. Database size and vector counts by namespace\n",
    "2. Metadata distribution analysis\n",
    "3. Vector distribution across landmarks\n",
    "4. Vector clustering and dimensionality reduction visualization\n",
    "\n",
    "These insights help us understand the structure and content of the vector database, enabling better optimization and usage of the data for landmark information retrieval."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc-landmarks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
